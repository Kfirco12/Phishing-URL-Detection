{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Kfir Cohen\n",
    "\n",
    "An implemention of the proposed algorithm in the paper: \n",
    "\"Malicious URLs Detection Using Decision Tree Classifiers and Majority Voting Technique\", by D. Patil and J. Patil\n",
    "\n",
    "I only used url features, without web-content features.The model I implemented is Random Forrest.\n",
    "\n",
    "\n",
    "Link to the paper: https://www.researchgate.net/publication/324014302_Malicious_URLs_Detection_Using_Decision_Tree_Classifiers_and_Majority_Voting_Technique\n",
    "\n",
    "Link to the Dataset: https://research.aalto.fi/en/datasets/phishstorm-phishing-legitimate-url-dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ipaddress as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features list (url features + suspicious words) acording to the referenced paper above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features list\n",
    "url_features = [\"url_len\", \"query_len\", \"tokens_num\", \"dots_num\", \"hyphens_num\",\\\n",
    "                   \"underscore_num\", \"equal_num\", \"f_slash_num\", \"q_mark_num\", \"semicolon_num\", \"o_parenthesis_num\", \\\n",
    "                   \"c_parenthesis_num\", \"mod_num\", \"amp_num\", \"at_num\", \"digit_num\",\"domain_ip_addr\"]\n",
    "\n",
    "suspicious_strings = [\"secure\", \"account\", \"webscr\", \"login\", \"ebayisapi\", \"signin\", \"banking\",\\\n",
    "                     \"confirm\", \"blog\", \"logon\", \"signon\", \"login.asp\", \"login.php\", \"login.htm\", \\\n",
    "                     \".exe\", \".zip\", \".rar\", \".jpg\", \".gif\", \"viewer.php\", \"link=\", \"getImage.asp\", \\\n",
    "                     \"plugins\", \"paypal\", \"order\", \"dbsys.php\", \"config.bin\", \"download.php\", \".js\", \\\n",
    "                     \"payment\", \"files\", \"css\", \"shopping\", \"mail.php\", \".jar\", \".swf\", \".cgi\", \".php\",\\\n",
    "                     \"abuse\", \"admin\", \".bin\", \"personal\", \"update\", \"verification\"]\n",
    "\n",
    "dataset_file = 'urls_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get url length.\n",
    "def get_url_len(url):\n",
    "    return len(url)\n",
    "\n",
    "# Get query length.\n",
    "def get_query_len(url):\n",
    "    query = urlparse(url).query\n",
    "    return len(query)\n",
    "\n",
    "#Count How many tokens are in the url.\n",
    "def count_tokens(url):\n",
    "    return(url.count('token='))\n",
    "\n",
    "# Get an array with the count of each charachter that was specified as suspicious.\n",
    "def get_charachters_count(url):\n",
    "    counter = Counter(url) # Count charachters so we won't need to read the string multiple times.\n",
    "    char_list = ['.','-','_','=','/','?',';','(',')','%','&','@']\n",
    "    return [counter[c] for c in char_list]\n",
    "\n",
    "# Count how many digits are in the url.\n",
    "def count_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "# Check if the domain is an IP Adress.\n",
    "def is_domain_ip(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    try:\n",
    "        if ip.ip_address(domain):\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Get a boolean list of the presence of the suspicious words in the url. \n",
    "def find_suspicious_words(url, suspicious_words):\n",
    "    existing_list = []\n",
    "    for word in suspicious_words:\n",
    "        if word in url:\n",
    "            existing_list.append(True)\n",
    "        else:\n",
    "            existing_list.append(False)\n",
    "    return existing_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the wanted features from the given url and appendinf the label.\n",
    "def get_features(url, label):\n",
    "    features = []\n",
    "    \n",
    "    #append the url features\n",
    "    features.append(get_url_len(url))\n",
    "    features.append(get_query_len(url))\n",
    "    features.append(count_tokens(url))\n",
    "    features += get_charachters_count(url)\n",
    "    features.append(count_digits(url))\n",
    "    features.append(is_domain_ip(url))\n",
    "\n",
    "    #append the suspicious words features\n",
    "    features += find_suspicious_words(url, suspicious_strings)\n",
    "    \n",
    "    # append the label\n",
    "    features.append(label)\n",
    "    \n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the data and extracting of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading data and shuffle\n",
    "data_set = pd.read_csv(dataset_file)\n",
    "data_set = data_set.sample(frac=1).reset_index(drop=True)\n",
    "data_set = data_set[data_set['label'].notna()]\n",
    "\n",
    "# extracting featuers from all the examples in the data set\n",
    "features_list = [] # Appending features to a list and convert the list to DataFrame is much fater than appending directly to the dataFrame.\n",
    "for i in range(len(data_set)):\n",
    "    features = get_features(data_set[\"url\"].loc[i], data_set[\"label\"].loc[i])\n",
    "    features_list.append(features)\n",
    "\n",
    "#Creates the features set\n",
    "features_list_df = pd.DataFrame(features_list)\n",
    "features_set = pd.DataFrame(features_list,columns = (url_features + [\"presence of \" + s for s in suspicious_strings] + ['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and training the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Spliting data to samples and labels\n",
    "X = features_set.drop(['label'],axis=1).values\n",
    "y = features_set['label'].values.astype('int')\n",
    "\n",
    "# Spliting the data to test and train data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.25, random_state=0)\n",
    "\n",
    "# Initializing the random forest model and training it.\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939541583696987\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
